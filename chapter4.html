<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>The LLM DNA: Tokens, Parameters & Prompts - Ask The Model</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Fira+Code&display=swap" rel="stylesheet">
  <script>
    tailwind.config = {
      theme: {
        extend: {
          fontFamily: {
            'inter': ['Inter', 'sans-serif'],
            'fira': ['Fira Code', 'monospace']
          }
        }
      }
    }
  </script>
</head>
<body class="bg-gray-900 text-gray-200 font-inter min-h-screen flex flex-col">
  <!-- Header Component -->
  <ask-the-model-header></ask-the-model-header>

  <div class="flex flex-col lg:flex-row flex-1">
    <!-- Sidebar Component -->
    <ask-the-model-sidebar></ask-the-model-sidebar>

    <!-- Main Content -->
    <main class="flex-1 p-4 md:p-8 lg:p-12 max-w-4xl mx-auto">
      <!-- Chapter Header -->
      <div class="mb-8">
        <h1 class="text-4xl md:text-5xl font-bold text-purple-400 mb-4">The LLM DNA: Tokens, Parameters & Prompts</h1>
        <p class="text-xl text-gray-300">Understanding the building blocks of language models</p>
      </div>

      <!-- Chapter Content -->
      <div class="space-y-8">
        <section class="bg-gray-800 p-6 rounded-lg border border-gray-700">
          <h2 class="text-2xl font-semibold text-purple-400 mb-4">What Are Tokens?</h2>
          <p class="text-gray-300 mb-4 leading-relaxed">
                    <strong>Tokens are the atomic units of text processing</strong>. LLMs convert text into numerical tokens via <strong>tokenization algorithms</strong> like Byte Pair Encoding (BPE). A single token might represent a word, subword, or character depending on the tokenizer.
                </p>
                <p class="text-gray-300 leading-relaxed">
                    The tokenization process is crucial because it determines how efficiently the model can process text and how much context it can handle in a single pass.
                </p>
                <div class="bg-gray-700 p-4 rounded-lg mt-4">
                    <h3 class="text-lg font-semibold text-purple-300 mb-2">Key Concepts:</h3>
                    <ul class="text-gray-300 text-sm space-y-1">
                        <li>• <strong>Token IDs:</strong> Numerical mappings for vocabulary elements</li>
                        <li>• <strong>Context Window:</strong> Maximum tokens the model can process simultaneously (e.g., 4K-32K tokens)</li>
                        <li>• <strong>Token Embeddings:</strong> Dense vector representations learned during training</li>
                        <li>• <strong>Subword Tokenization:</strong> Breaking words into smaller units for better coverage</li>
                    </ul>
                </div>
        </section>
        <section class="bg-gray-800 p-6 rounded-lg border border-gray-700">
          <h2 class="text-2xl font-semibold text-purple-400 mb-4">Parameters: The Model's Knowledge</h2>
          <p class="text-gray-300 mb-4 leading-relaxed">
                    <strong>Parameters are the learnable weights and biases that encode model knowledge</strong>. In neural networks, <strong>weights determine connection strength between neurons, while biases provide activation thresholds</strong>.
                </p>
                <p class="text-gray-300 leading-relaxed">
                    These parameters are what the model learns during training - they represent the patterns, relationships, and knowledge extracted from the massive training datasets.
                </p>
                <div class="bg-gray-700 p-4 rounded-lg mt-4">
                    <h3 class="text-lg font-semibold text-purple-300 mb-2">Parameter Calculation:</h3>
                    <p class="text-gray-300 text-sm">For a layer with <strong>m</strong> inputs and <strong>n</strong> outputs: <strong>(m × n) weights + n biases</strong>. Modern LLMs contain billions of these trainable coefficients.</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-4 mt-4">
                    <div class="bg-gray-700 p-4 rounded-lg">
                        <h3 class="text-lg font-semibold text-purple-300 mb-2">Weight Parameters</h3>
                        <p class="text-gray-300 text-sm">Control how strongly input features influence the output, learned through backpropagation</p>
                    </div>
                    <div class="bg-gray-700 p-4 rounded-lg">
                        <h3 class="text-lg font-semibold text-purple-300 mb-2">Bias Parameters</h3>
                        <p class="text-gray-300 text-sm">Provide activation thresholds, helping neurons decide when to "fire"</p>
                    </div>
                </div>
        </section>
        <section class="bg-gray-800 p-6 rounded-lg border border-gray-700">
          <h2 class="text-2xl font-semibold text-purple-400 mb-4">Prompts: Your Instructions</h2>
          <p class="text-gray-300 mb-4 leading-relaxed">
                    <strong>Prompts are input instructions that guide model behavior</strong>. Unlike traditional programming, LLMs are <strong>conditioned through natural language instructions</strong> rather than code. Effective prompting requires understanding how models interpret and respond to different input patterns.
                </p>
                <div class="bg-gray-700 p-4 rounded-lg mt-4">
                    <h3 class="text-lg font-semibold text-purple-300 mb-2">Prompt Types:</h3>
                    <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
                        <div>
                            <h4 class="text-purple-300 font-semibold mb-2">Instruction Prompts</h4>
                            <p class="text-gray-300 text-sm">Direct commands like "Write a summary of..." or "Explain how..."</p>
                        </div>
                        <div>
                            <h4 class="text-purple-300 font-semibold mb-2">Few-Shot Prompts</h4>
                            <p class="text-gray-300 text-sm">Provide examples of desired input-output patterns</p>
                        </div>
                        <div>
                            <h4 class="text-purple-300 font-semibold mb-2">Role-Based Prompts</h4>
                            <p class="text-gray-300 text-sm">"Act as a teacher" or "You are a coding expert"</p>
                        </div>
                        <div>
                            <h4 class="text-purple-300 font-semibold mb-2">Chain-of-Thought</h4>
                            <p class="text-gray-300 text-sm">Ask the model to show its reasoning process</p>
                        </div>
                    </div>
                </div>
        </section>
        <!-- Chapter Navigation Component -->
        <ask-the-model-chapter-nav></ask-the-model-chapter-nav>
      </div>
    </main>
  </div>
  
  <!-- Footer Component -->
  <ask-the-model-footer></ask-the-model-footer>

  <!-- Mobile Navigation Component -->
  <ask-the-model-mobile-nav></ask-the-model-mobile-nav>

  <!-- Web Components Script -->
  <script src="web-components.js"></script>
</body>
</html>